#include <iostream>
#include <fstream>
#include <sstream>
#include <vector>
#include <set>
#include <map>
#include <algorithm>
#include <string>
using namespace std;

// ---------- CSV Writer ----------
void writeCSV(const string &filename, const vector<vector<string>> &rows) {
    ofstream file(filename);
    for (auto &row : rows) {
        for (size_t i = 0; i < row.size(); i++) {
            file << row[i];
            if (i != row.size() - 1)
                file << ",";
        }
        file << "\n";
    }
    file.close();
}

// ---------- Candidate Generator ----------
vector<set<string>> generateCandidates(const vector<set<string>> &prevFreq, int k) {
    vector<set<string>> candidates;
    for (size_t i = 0; i < prevFreq.size(); i++) {
        for (size_t j = i + 1; j < prevFreq.size(); j++) {
            set<string> c;
            set_union(prevFreq[i].begin(), prevFreq[i].end(),
                      prevFreq[j].begin(), prevFreq[j].end(),
                      inserter(c, c.begin()));
            if ((int)c.size() == k)
                candidates.push_back(c);
        }
    }
    sort(candidates.begin(), candidates.end());
    candidates.erase(unique(candidates.begin(), candidates.end()), candidates.end());
    return candidates;
}

// ---------- Support Counter ----------
map<set<string>, int> countSupport(const vector<set<string>> &transactions,
                                   const vector<set<string>> &candidates) {
    map<set<string>, int> supportCount;
    for (auto &c : candidates) {
        for (auto &t : transactions) {
            if (includes(t.begin(), t.end(), c.begin(), c.end())) {
                supportCount[c]++;
            }
        }
    }
    return supportCount;
}

// ---------- Apriori Algorithm ----------
void apriori(const vector<set<string>> &transactions, double minSupport, double minConfidence) {
    int totalTransactions = transactions.size();
    vector<set<string>> oneItemsets;
    set<string> allItems;

    // Step 1: Collect all unique items
    for (auto &t : transactions)
        for (auto &item : t)
            allItems.insert(item);

    for (auto &item : allItems)
        oneItemsets.push_back({item});

    vector<vector<set<string>>> allFrequentSets;
    int k = 1;

    vector<vector<string>> freqCSV = {{"Itemset", "Support"}};
    vector<vector<string>> rulesCSV = {{"Antecedent", "Consequent", "Support", "Confidence"}};

    // Step 2: Generate frequent itemsets iteratively
    while (true) {
        map<set<string>, int> supportCount = countSupport(transactions, oneItemsets);

        vector<set<string>> freqItemsets;
        for (auto &p : supportCount) {
            double support = (double)p.second / totalTransactions;
            if (support >= minSupport) {
                freqItemsets.push_back(p.first);

                string items = "";
                for (auto &i : p.first)
                    items += i + " ";
                freqCSV.push_back({items, to_string(support)});
            }
        }

        if (freqItemsets.empty())
            break;

        allFrequentSets.push_back(freqItemsets);
        oneItemsets = generateCandidates(freqItemsets, ++k);
    }

    // Step 3: Print Frequent Itemsets
    cout << "\n=== Frequent Itemsets (minSup=" << minSupport << ") ===\n";
    for (auto &level : allFrequentSets) {
        for (auto &s : level) {
            for (auto &item : s)
                cout << item << " ";
            cout << endl;
        }
    }

    // Step 4: Generate Association Rules
    cout << "\n=== Association Rules (minConf=" << minConfidence << ") ===\n";
    for (auto &level : allFrequentSets) {
        for (auto &itemset : level) {
            if (itemset.size() < 2)
                continue;

            vector<string> items(itemset.begin(), itemset.end());
            int n = items.size();

            for (int mask = 1; mask < (1 << n) - 1; mask++) {
                set<string> antecedent, consequent;
                for (int i = 0; i < n; i++) {
                    if (mask & (1 << i))
                        antecedent.insert(items[i]);
                    else
                        consequent.insert(items[i]);
                }

                // Compute supports
                map<set<string>, int> supCount = countSupport(transactions, {itemset, antecedent});
                double supportItemset = (double)supCount[itemset] / totalTransactions;
                double supportAntecedent = (double)supCount[antecedent] / totalTransactions;

                if (supportAntecedent == 0)
                    continue;

                double confidence = supportItemset / supportAntecedent;

                if (supportItemset >= minSupport && confidence >= minConfidence) {
                    cout << "{ ";
                    for (auto &a : antecedent)
                        cout << a << " ";
                    cout << "} => { ";
                    for (auto &c : consequent)
                        cout << c << " ";
                    cout << "} (support=" << supportItemset
                         << ", confidence=" << confidence << ")\n";

                    string ant = "", con = "";
                    for (auto &a : antecedent)
                        ant += a + " ";
                    for (auto &c : consequent)
                        con += c + " ";
                    rulesCSV.push_back({ant, con,
                                        to_string(supportItemset),
                                        to_string(confidence)});
                }
            }
        }
    }

    // Step 5: Write results to CSV files
    writeCSV("frequent_itemsets.csv", freqCSV);
    writeCSV("association_rules.csv", rulesCSV);

    cout << "\nCSV files generated: frequent_itemsets.csv, association_rules.csv\n";
}

// ---------- Read Transactions from CSV ----------
vector<set<string>> readTransactions(const string &filename) {
    vector<set<string>> transactions;
    ifstream file(filename);
    string line;
    while (getline(file, line)) {
        set<string> transaction;
        stringstream ss(line);
        string item;
        while (getline(ss, item, ',')) {
            if (!item.empty()) {
                // Remove leading/trailing spaces
                item.erase(remove_if(item.begin(), item.end(), ::isspace), item.end());
                transaction.insert(item);
            }
        }
        if (!transaction.empty())
            transactions.push_back(transaction);
    }
    return transactions;
}

// ---------- Main ----------
int main() {
    string inputFile;
    double minSupport, minConfidence;

    cout << "Enter CSV file name (e.g. transactions.csv): ";
    cin >> inputFile;

    cout << "Enter minimum support (e.g. 0.5 for 50%): ";
    cin >> minSupport;

    cout << "Enter minimum confidence (e.g. 0.7 for 70%): ";
    cin >> minConfidence;

    vector<set<string>> transactions = readTransactions(inputFile);
    if (transactions.empty()) {
        cout << "No transactions found in " << inputFile << endl;
        return 0;
    }

    apriori(transactions, minSupport, minConfidence);
    return 0;
}

// ==================================================================================================
// üîπ DETAILED EXPLANATION OF THE APRIORI CODE (STEP-BY-STEP WITH INTERNAL LOGIC)
// ==================================================================================================
//
// üß© PURPOSE:
// This program implements the **Apriori Algorithm**, one of the most important techniques
// in Data Mining for **Association Rule Mining (ARM)**.
// It‚Äôs used to find frequent item combinations and strong relationships between items
// ‚Äî typically applied in **Market Basket Analysis** (e.g., analyzing which products are often bought together).
//
// --------------------------------------------------------------------------------------------------
// üî∏ PART 1: HEADER FILES & SETUP
// --------------------------------------------------------------------------------------------------
//
// ‚Üí #include directives bring standard C++ libraries for file handling, string manipulation, and data structures.
// ‚Üí STL containers like `vector`, `set`, and `map` are heavily used for storing transactions and counting support.
//
//    - vector<vector<string>> ‚Üí 2D structure to hold CSV rows
//    - set<string> ‚Üí used for each transaction (automatically removes duplicates)
//    - map<set<string>, int> ‚Üí tracks how many times each itemset appears (support count)
//
// --------------------------------------------------------------------------------------------------
// üî∏ PART 2: writeCSV()
// --------------------------------------------------------------------------------------------------
//
// ‚Ä¢ Purpose: Save results (frequent itemsets and rules) into separate .csv files for later inspection.
// ‚Ä¢ It loops through each ‚Äúrow‚Äù (vector<string>) and writes values separated by commas.
// ‚Ä¢ Example Output Files:
//     - frequent_itemsets.csv ‚Üí Itemset + Support value
//     - association_rules.csv ‚Üí Antecedent + Consequent + Support + Confidence
//
// --------------------------------------------------------------------------------------------------
// üî∏ PART 3: generateCandidates()
// --------------------------------------------------------------------------------------------------
//
// ‚Ä¢ Core idea: Combine frequent itemsets of size (k‚àí1) to generate candidates of size k.
// ‚Ä¢ Uses `set_union()` to merge two sets if their combined size == k.
// ‚Ä¢ Example: If {milk, bread} and {milk, butter} are frequent (2-itemsets),
//   they generate candidate {milk, bread, butter} (3-itemset).
// ‚Ä¢ After generating all candidates, duplicates are removed using sort() and unique().
//
// --------------------------------------------------------------------------------------------------
// üî∏ PART 4: countSupport()
// --------------------------------------------------------------------------------------------------
//
// ‚Ä¢ Purpose: Count how often each candidate itemset appears in all transactions.
// ‚Ä¢ For each candidate set, it checks whether the transaction contains all candidate items using `includes()`.
// ‚Ä¢ Support count is stored in a map: `map<set<string>, int> supportCount`.
// ‚Ä¢ Example: if {milk, bread} appears in 3 of 5 transactions ‚Üí supportCount[{milk,bread}] = 3.
//
// --------------------------------------------------------------------------------------------------
// üî∏ PART 5: apriori()
// --------------------------------------------------------------------------------------------------
//
// This function implements the **entire Apriori process**:
//
//   Step 1Ô∏è‚É£ ‚Äî Extract all unique items from dataset.
//       - A set of all single items is created ‚Üí initial 1-itemsets.
//
//   Step 2Ô∏è‚É£ ‚Äî Count support for 1-itemsets.
//       - Using countSupport(), support = occurrences / total_transactions.
//       - Only items with support ‚â• minSupport are kept as ‚Äúfrequent‚Äù.
//
//   Step 3Ô∏è‚É£ ‚Äî Generate next-level itemsets.
//       - Using generateCandidates(), create 2-item, 3-item, ‚Ä¶ sets.
//       - Repeat support counting and pruning until no new frequent itemsets appear.
//
//   Step 4Ô∏è‚É£ ‚Äî Print and store frequent itemsets.
//       - Each frequent itemset and its support are printed on screen
//         and also written into `frequent_itemsets.csv`.
//
// --------------------------------------------------------------------------------------------------
// üî∏ PART 6: GENERATING ASSOCIATION RULES
// --------------------------------------------------------------------------------------------------
//
// ‚Ä¢ Once all frequent itemsets are known, the algorithm creates rules of the form:
//       Antecedent ‚Üí Consequent
//
//   Example: {Milk, Bread} ‚Üí {Butter}
//
// ‚Ä¢ For every frequent itemset with at least 2 items, it generates all possible
//   combinations of antecedent and consequent by binary masking (`mask` loop).
//
// ‚Ä¢ Then it calculates:
//     - support(Itemset) = count(Itemset) / totalTransactions
//     - support(Antecedent) = count(Antecedent) / totalTransactions
//     - confidence = support(Itemset) / support(Antecedent)
//
// ‚Ä¢ Rules that satisfy:
//       support ‚â• minSupport  AND  confidence ‚â• minConfidence
//   are considered **strong rules** and displayed.
//
// ‚Ä¢ Example rule in output:
//       { Milk } => { Bread } (support=0.6, confidence=0.8)
//
// --------------------------------------------------------------------------------------------------
// üî∏ PART 7: OUTPUT & CSV STORAGE
// --------------------------------------------------------------------------------------------------
//
// ‚Ä¢ The algorithm prints all frequent itemsets and rules on the console for verification.
// ‚Ä¢ Then it writes them into two CSV files:
//     1Ô∏è‚É£ frequent_itemsets.csv
//     2Ô∏è‚É£ association_rules.csv
//
// ‚Ä¢ These files can later be visualized in Excel or any data visualization tool.
//
// --------------------------------------------------------------------------------------------------
// üî∏ PART 8: readTransactions()
// --------------------------------------------------------------------------------------------------
//
// ‚Ä¢ Reads the CSV input file line by line.
// ‚Ä¢ Each line represents a transaction (like a shopping basket).
// ‚Ä¢ The function splits the line by commas, trims spaces, and inserts each item into a set.
// ‚Ä¢ Example input line:  ‚Äúmilk,bread,butter‚Äù  ‚Üí  transaction = {milk, bread, butter}
// ‚Ä¢ Finally returns a vector of all transactions.
//
// --------------------------------------------------------------------------------------------------
// üî∏ PART 9: main()
// --------------------------------------------------------------------------------------------------
//
// ‚Ä¢ Takes user inputs:
//       - File name (e.g., ‚Äúgroceries.csv‚Äù)
//       - Minimum support (e.g., 0.3 ‚Üí 30%)
//       - Minimum confidence (e.g., 0.6 ‚Üí 60%)
//
// ‚Ä¢ Calls readTransactions() ‚Üí loads data
// ‚Ä¢ Calls apriori() ‚Üí runs algorithm
// ‚Ä¢ If no data is found, exits gracefully.
//
// --------------------------------------------------------------------------------------------------
// üî∏ PART 10: SAMPLE RUN
// --------------------------------------------------------------------------------------------------
//
// Input:
//     transactions.csv
//     minSupport = 0.3
//     minConfidence = 0.7
//
// Output:
//     === Frequent Itemsets (minSup=0.3) ===
//     milk
//     bread
//     milk bread
//
//     === Association Rules (minConf=0.7) ===
//     { milk } => { bread } (support=0.6, confidence=0.8)
//
// Generated Files:
//     frequent_itemsets.csv
//     association_rules.csv
//
// --------------------------------------------------------------------------------------------------
// üî∏ INTERNAL LOGIC SUMMARY
// --------------------------------------------------------------------------------------------------
//
// The Apriori algorithm follows the **‚Äúbottom-up‚Äù** approach:
//
//     - Start with 1-itemsets
//     - Use them to build 2-itemsets
//     - Continue until no larger frequent itemsets exist
//
// It uses the **Apriori property**:
//     ‚Üí If an itemset is frequent, all its subsets are also frequent.
//     ‚Üí If an itemset is not frequent, none of its supersets will be frequent.
//
// This property helps in **pruning** unnecessary candidate itemsets,
// making the algorithm efficient.
//
// --------------------------------------------------------------------------------------------------
// üîπ WHY APRIORI METHOD IS CHOSEN FOR THIS CODE
// --------------------------------------------------------------------------------------------------
//
// 1Ô∏è‚É£ Data Type Suitability:
//     - The dataset (like Groceries) is transactional: each record is a set of items.
//     - No class label or numeric target ‚Üí classification/regression not applicable.
//     - We only need to find relationships between co-occurring items.
//
// 2Ô∏è‚É£ Purpose of Analysis:
//     - Identify patterns such as:
//           ‚ÄúIf a customer buys milk and butter, they are likely to buy bread.‚Äù
//     - This is **Market Basket Analysis**, and Apriori is the standard technique for it.
//
// 3Ô∏è‚É£ Advantages of Apriori:
//     - Simple and interpretable algorithm.
//     - Efficiently eliminates infrequent itemsets using its pruning property.
//     - Generates meaningful rules that can be used for recommendations.
//
// 4Ô∏è‚É£ Why Not Other Methods:
//     - **Decision Trees / Naive Bayes:** Need a predefined target (not available here).
//     - **Clustering:** Groups data, but doesn‚Äôt show item dependencies.
//     - **Regression:** Predicts numeric values, not relationships.
//
// ‚úÖ Hence, Apriori perfectly fits for transactional pattern discovery.
//
// --------------------------------------------------------------------------------------------------
// üîπ CONCLUSION
// --------------------------------------------------------------------------------------------------
//
// ‚Ä¢ The Apriori algorithm successfully finds all frequent item combinations
//   that meet the minimum support threshold.
//
// ‚Ä¢ It then derives strong association rules that satisfy both support and confidence constraints.
//
// ‚Ä¢ These rules can be interpreted as *if‚Äìthen* statements useful in business intelligence,
//   customer behavior analysis, or recommendation systems.
//
// ‚Ä¢ Example Insight:
//       "If customers buy butter and milk, 80% of them also buy bread."
//
// ‚Ä¢ The generated CSV files can be used for visualization or integration with other analytics tools.
//
// --------------------------------------------------------------------------------------------------
// ‚úÖ FINAL REMARK:
// This experiment demonstrates **Association Rule Mining using Apriori** ‚Äî
// one of the most fundamental and interpretable techniques in Data Mining.
// It effectively uncovers hidden patterns from transactional data without requiring labeled outputs.
//
// ==================================================================================================
